{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q llama-index\n",
        "! pip install -q deeplake langchain pypdf\n",
        "! pip install -q tensorflow_text  deeplake\n"
      ],
      "metadata": {
        "id": "V1p6TH7q5z6F"
      },
      "id": "V1p6TH7q5z6F",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-cloud-aiplatform\n",
        "!pip install -q  trulens-eval\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjAJQyoeBpP2",
        "outputId": "403b4b5e-f392-45d5-fcf1-f304b8cb9b3b"
      },
      "id": "yjAJQyoeBpP2",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m623.5/623.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.4/179.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.7/194.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.8/283.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.4/518.4 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.6/230.6 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.5/680.5 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.4/635.4 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.3/624.3 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.1/241.1 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for millify (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9bff53e",
      "metadata": {
        "id": "a9bff53e"
      },
      "source": [
        "# Lesson 1: Advanced RAG Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "feb98470-c136-471d-a63e-d50d8eb09c57",
      "metadata": {
        "height": 98,
        "tags": [],
        "id": "feb98470-c136-471d-a63e-d50d8eb09c57"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://wordpress.deeplearning.ai/wp-content/uploads/2022/10/eBook-How-to-Build-a-Career-in-AI.pdf\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iLEJm7T6yLN",
        "outputId": "7d2c680e-1956-4539-c7ba-fe610e467e88"
      },
      "id": "_iLEJm7T6yLN",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-02 05:44:39--  https://wordpress.deeplearning.ai/wp-content/uploads/2022/10/eBook-How-to-Build-a-Career-in-AI.pdf\n",
            "Resolving wordpress.deeplearning.ai (wordpress.deeplearning.ai)... 164.92.64.128\n",
            "Connecting to wordpress.deeplearning.ai (wordpress.deeplearning.ai)|164.92.64.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3717673 (3.5M) [application/pdf]\n",
            "Saving to: ‘eBook-How-to-Build-a-Career-in-AI.pdf.1’\n",
            "\n",
            "eBook-How-to-Build- 100%[===================>]   3.54M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-12-02 05:44:40 (28.3 MB/s) - ‘eBook-How-to-Build-a-Career-in-AI.pdf.1’ saved [3717673/3717673]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "31e2859b-596e-40b3-867b-f4d6e91f74bc",
      "metadata": {
        "height": 98,
        "tags": [],
        "id": "31e2859b-596e-40b3-867b-f4d6e91f74bc"
      },
      "outputs": [],
      "source": [
        "from llama_index import SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\n",
        "    input_files=[\"./eBook-How-to-Build-a-Career-in-AI.pdf\"]\n",
        ").load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2d7d0857-b9d1-4feb-8243-bfd2f4953acd",
      "metadata": {
        "height": 81,
        "tags": [],
        "id": "2d7d0857-b9d1-4feb-8243-bfd2f4953acd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f068be2-646c-449a-c7c6-0c8ca16111cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> \n",
            "\n",
            "41 \n",
            "\n",
            "<class 'llama_index.schema.Document'>\n",
            "Doc ID: 87a784c3-8e6f-463a-bdf3-5c8db4cb65db\n",
            "Text: PAGE 1Founder, DeepLearning.AICollected Insights from Andrew Ng\n",
            "How to  Build Your Career in AIA Simple Guide\n"
          ]
        }
      ],
      "source": [
        "print(type(documents), \"\\n\")\n",
        "print(len(documents), \"\\n\")\n",
        "print(type(documents[0]))\n",
        "print(documents[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3123d3d",
      "metadata": {
        "id": "f3123d3d"
      },
      "source": [
        "## Basic RAG pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b4abc806-64f5-46bb-8c9f-6469ecb18d20",
      "metadata": {
        "height": 64,
        "tags": [],
        "id": "b4abc806-64f5-46bb-8c9f-6469ecb18d20"
      },
      "outputs": [],
      "source": [
        "from llama_index import Document\n",
        "\n",
        "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "nBPmr0FL7VVc"
      },
      "id": "nBPmr0FL7VVc",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from langchain.llms import VertexAI\n",
        "\n",
        "PROJECT_ID = 'zeta-yen-319702'\n",
        "REGION = 'us-central1'\n",
        "BUCKET = 'gs://zeta-yen-319702-temp/'\n",
        "\n",
        "#os.environ['GOOGLE_APPLICATION_CREDENTIALS'] =\n",
        "\n",
        "vertexai.init(\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        "    staging_bucket=BUCKET\n",
        ")"
      ],
      "metadata": {
        "id": "7Grw4HHG72tF"
      },
      "id": "7Grw4HHG72tF",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.vertex import Vertex\n",
        "from llama_index.llms.base import ChatMessage, MessageRole, CompletionResponse\n",
        "\n",
        "llm = Vertex(model=\"text-bison\", temperature=0, additional_kwargs={})\n",
        "llm.complete(\"Hello this is a sample text\").text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rBJtbxGv7umy",
        "outputId": "7ea7eb8a-2da3-4506-92f6-759a00f90dae"
      },
      "id": "rBJtbxGv7umy",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' ```\\nHello this is a sample text\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = Vertex(model=\"chat-bison\")\n",
        "messages = [\n",
        "    ChatMessage(role=MessageRole.SYSTEM, content=\"Reply everything in french\"),\n",
        "    ChatMessage(role=MessageRole.USER, content=\"Hello\"),\n",
        "]\n",
        "chat.chat(messages=messages).message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OBiQQrYzHxMs",
        "outputId": "e09a22c4-31d3-440b-adff-d814f06f69a9"
      },
      "id": "OBiQQrYzHxMs",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Bonjour! Comment vas-tu?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import TensorflowHubEmbeddings\n",
        "from langchain.vectorstores import DeepLake\n",
        "url = \"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\"\n",
        "embed_model = TensorflowHubEmbeddings(model_url=url)"
      ],
      "metadata": {
        "id": "6hifWl_j8Ju8"
      },
      "id": "6hifWl_j8Ju8",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "afc2baff-5e8b-4733-9899-16f248777b23",
      "metadata": {
        "height": 183,
        "tags": [],
        "id": "afc2baff-5e8b-4733-9899-16f248777b23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee9219a-974a-4d17-cb27-d357224ce2d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r\r\r\r"
          ]
        }
      ],
      "source": [
        "from llama_index import VectorStoreIndex\n",
        "from llama_index import ServiceContext\n",
        "from llama_index.vector_stores import DeepLakeVectorStore\n",
        "from llama_index.storage.storage_context import StorageContext\n",
        "\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    llm=chat, embed_model=embed_model\n",
        ")\n",
        "\n",
        "dataset_path = \"paul_graham_essay\"\n",
        "\n",
        "# Create an index over the documnts\n",
        "vector_store = DeepLakeVectorStore(dataset_path=dataset_path, overwrite=True)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "index = VectorStoreIndex.from_documents([document],\n",
        "                                        service_context=service_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "ae52a26c-7d0c-44df-8043-4c7f19f794b9",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "ae52a26c-7d0c-44df-8043-4c7f19f794b9"
      },
      "outputs": [],
      "source": [
        "query_engine = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "6b0d5b6e-cc2e-4648-b28c-5fa25a97d175",
      "metadata": {
        "height": 81,
        "tags": [],
        "id": "6b0d5b6e-cc2e-4648-b28c-5fa25a97d175",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e56b811-73b7-4f80-888f-53f5856fca31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1) Join existing projects. \n",
            "2) Keep reading and talking to people. \n",
            "3) Focus on an application area. \n",
            "4) Develop a side hustle. \n"
          ]
        }
      ],
      "source": [
        "\n",
        "response = query_engine.query(\n",
        "    \"What are steps to take when finding projects to build your experience?\"\n",
        ")\n",
        "print(str(response))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}